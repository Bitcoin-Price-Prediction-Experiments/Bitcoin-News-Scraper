{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "958faca1-4ed8-4d4a-9ff1-0ca73f36aab4",
   "metadata": {},
   "source": [
    "# Extracting News Article Descriptions from Yahoo Finance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd803e5-4365-418f-83a5-ceee4ad5d5eb",
   "metadata": {},
   "source": [
    "**\\[Last Updated: Sep 13, 2024]**\n",
    "\n",
    "Stay informed about the latest Bitcoin news on **Yahoo Finance** by visiting this link: https://finance.yahoo.com/quote/BTC-USD/.\n",
    "\n",
    "Our goal is to gather and structure descriptions of [Yahoo Finance](https://finance.yahoo.com/quote/BTC-USD/) news articles. Since the publication dates aren’t immediately visible, we’ll begin by scraping both the article URLs and descriptions. We’ll then visit each URL to retrieve the publication date from within the article. Afterward, we’ll map the extracted dates with the corresponding article descriptions to maintain proper sequencing and ensure accurate data association.\n",
    "\n",
    "After obtaining the correct mapping between the article descriptions and their publication dates, we will generate a summary of each article using a [pre-trained transformer model](https://huggingface.co/Mr-Vicky-01/Bart-Finetuned-conversational-summarization). This model is designed to distill the key points of the articles, providing concise and informative summaries for easy reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc09c606-77b5-45fd-9de9-282843b6e0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "if (!(\"Notification\" in window)) {\n    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n    Notification.requestPermission(function (permission) {\n        if(!('permission' in Notification)) {\n            Notification.permission = permission;\n        }\n    })\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyternotify\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b83f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from chromedriver_py import binary_path\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dff64e0-4452-4707-9885-eac25ea16d0c",
   "metadata": {},
   "source": [
    "## Part One: Extracting News Descriptions and Their Publication Dates\n",
    "In this section, we will use Selenium, a powerful web scraping tool, to extract news descriptions and their publication dates. Selenium allows us to automate web browsers, interact with web pages, and extract data efficiently, by simulating user interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9985709c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index scrolling: 0\n",
      "index scrolling: 1\n",
      "index scrolling: 2\n",
      "index scrolling: 3\n",
      "index scrolling: 4\n",
      "index scrolling: 5\n",
      "index scrolling: 6\n",
      "index scrolling: 7\n",
      "index scrolling: 8\n",
      "index scrolling: 9\n",
      "Reached the end of the page.\n"
     ]
    }
   ],
   "source": [
    "options = Options()\n",
    "\n",
    "svc = webdriver.ChromeService(executable_path=binary_path)\n",
    "capabilities = DesiredCapabilities.CHROME.copy()  \n",
    "\n",
    "driver = webdriver.Chrome(service=svc)\n",
    "driver.get(\"https://finance.yahoo.com/quote/BTC-USD/news\")\n",
    "\n",
    "driver.execute_script(\"window.stop();\")\n",
    "\n",
    "scroll_pause_time = 2  # Adjust as needed\n",
    "index_page = 0\n",
    "\n",
    "previous_height = driver.execute_script('return document.body.scrollHeight')\n",
    "\n",
    "while index_page < 100: # Adjust as needed\n",
    "\n",
    "    print(f\"index scrolling: {index_page}\")\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    time.sleep(scroll_pause_time)\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    index_page += 1\n",
    "    \n",
    "    if new_height == previous_height:\n",
    "        print(\"Reached the end of the page.\")\n",
    "        break\n",
    "\n",
    "    previous_height = new_height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb5f09a-0b0d-4d20-9e1b-69c21031b22e",
   "metadata": {},
   "source": [
    "### Note: Keep in mind that the XPaths of HTML elements below may change over time, so it's important to update them as needed.\n",
    "Feel free to replace the selectors with their latest versions when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33434521-43b2-4330-bdad-e0233c6e205a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titles = np.array([])\n",
    "descriptions = np.array([])\n",
    "urls = np.array([])\n",
    "dates = np.array([])\n",
    "\n",
    "elements = driver.find_elements(By.XPATH, \"//li[@class='stream-item  yf-7rcxn']\") # Verify and update the XPath if this selector becomes outdated\n",
    "\n",
    "for element in elements:\n",
    "    description = element.find_element(By.XPATH, \".//p[contains(@class,'clamp  yf-1e4au4k')]\").text # Verify and update the XPath if this selector becomes outdated\n",
    "    descriptions = np.append(descriptions, description)\n",
    "\n",
    "    url = element.find_element(By.XPATH, \".//a[contains(@class,'subtle-link fin-size-small titles noUnderline yf-13p9sh2')]\").get_attribute('href') # Verify and update the XPath if this selector becomes outdated\n",
    "    urls = np.append(urls, url)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30703b60-a2bf-4e16-82da-978170896b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,) (200,)\n"
     ]
    }
   ],
   "source": [
    "print(descriptions.shape, urls.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e682ec-ce54-4fc0-87f7-38e9a932bc2d",
   "metadata": {},
   "source": [
    "### In the following cells, we will access each URL to extract the publication date of the corresponding article, and then, convert those collected dates to datetime objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4bdfd6-7992-4046-adb5-1bae3705012b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index_url, url in enumerate(urls):\n",
    "    ## Uncomment the line below to track the progress of accessed URLs\n",
    "    # print(f\"URL N°{index_url} : {url}\")\n",
    "    driver.get(url)\n",
    "    date = driver.find_element(By.XPATH, \"//time\").text\n",
    "    dates = np.append(dates, date)\n",
    "    ## Uncomment the line below to check the extracted dates\n",
    "    # print(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97d3078-eda8-483f-9c07-1cc8b942a797",
   "metadata": {},
   "source": [
    "#### It's evident here that many articles have different date formats, so we will standardize them into a uniform format to ensure consistency across all entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9f2964-dbb2-4798-8c77-ad5d1588a130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def format_dates(dates):\n",
    "    formatted_dates = np.array([])\n",
    "    date_formats = [\n",
    "        \"%a, %B %d, %Y at %I:%M %p GMT+1\",   # Example format with time and GMT+1\n",
    "        \"%a, %B %d, %Y, %I:%M %p\",           # Format with time but no GMT+1\n",
    "        \"%a, %b %d, %Y, %I:%M %p\",           # Format with time and short month name\n",
    "        \"%a, %b %d, %Y\",                     # Format without time and short month name\n",
    "        \"%B %d, %Y\"                          # Format without day of the week and time\n",
    "    ]\n",
    "\n",
    "    for date_str in dates:\n",
    "        parsed = False\n",
    "        for date_format in date_formats:\n",
    "            try:\n",
    "                date_object = datetime.strptime(date_str, date_format)\n",
    "                formatted_dates = np.append(formatted_dates, date_object.strftime(\"%Y-%m-%d\"))\n",
    "                parsed = True\n",
    "                break\n",
    "            except ValueError:\n",
    "                continue\n",
    "        \n",
    "        if not parsed:\n",
    "            print(f\"Error parsing date '{date_str}'\")\n",
    "            formatted_dates = np.append(formatted_dates, 'Invalid Date')\n",
    "\n",
    "    return formatted_dates\n",
    "    \n",
    "formatted_dates_array = format_dates(dates)\n",
    "## Uncomment the line below to view the array of the formatted dates\n",
    "# print(formatted_dates_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91954c49-0559-45bf-8e27-5329644c96ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_dates_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1c3322-ee22-44ba-aab6-fead89e38222",
   "metadata": {},
   "source": [
    "#### Sort and convert dates to datetime objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42ba7566-2ffc-44ee-bc54-92943112e1d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dates_datetime = np.array([np.datetime64(date) for date in formatted_dates_array])\n",
    "\n",
    "sorted_indices = np.argsort(dates_datetime)[::-1]\n",
    "sorted_dates = np.array(formatted_dates_array)[sorted_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87152756-9eb3-4930-a33c-82ecb0ae426b",
   "metadata": {},
   "source": [
    "## Part Two: Summarizing the Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4431434f-fa75-459c-92c4-cc9ec29bdb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Mr-Vicky-01/Bart-Finetuned-conversational-summarization\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Mr-Vicky-01/Bart-Finetuned-conversational-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed06bc2-6edb-4755-8118-984a4ce9cad6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_summary(text):\n",
    "    inputs = tokenizer([text], max_length=1024, return_tensors='pt', truncation=True)\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_new_tokens=80, do_sample=False)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "short_descriptions = np.array([])\n",
    "\n",
    "for i, description in enumerate(descriptions):\n",
    "    short_description = generate_summary(description)\n",
    "    ## Uncomment the line below to track the progress of summarized descriptions\n",
    "    # print(f'Description N°{i+1}')\n",
    "    short_descriptions = np.append(short_descriptions, short_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "877da7f1-493d-4f66-8574-f54e2d594e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "print(short_descriptions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2673052b-c657-432c-ba51-e8588040ec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Date' : sorted_dates,\n",
    "    'Description' : descriptions,\n",
    "    'Short Description' : short_descriptions \n",
    "})\n",
    "\n",
    "df.set_index('Date', inplace=True)\n",
    "df = df.sort_index(ascending=False)\n",
    "df.index = pd.to_datetime(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5844d99f-44aa-4304-ba01-fc715b4dff21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Short Description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-09-12</th>\n",
       "      <td>Digital-trading platform eToro USA agreed to p...</td>\n",
       "      <td>eToro USA has agreed to limit its crypto offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-12</th>\n",
       "      <td>High-leverage liquidity in bitcoin is concentr...</td>\n",
       "      <td>in bitcoin is concentrated at around $58,500,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-11</th>\n",
       "      <td>The Kamala Harris-Donald Trump debate sent rip...</td>\n",
       "      <td>The Kamala Harris-Donald Trump debate sent rip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-11</th>\n",
       "      <td>US stocks (^DJI, ^IXIC, ^GSPC) were trading lo...</td>\n",
       "      <td>US stocks are trading lower on Wednesday morni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-11</th>\n",
       "      <td>Trump trades slumped following Tuesday's presi...</td>\n",
       "      <td>Trump trades slumped following Tuesday's presi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-22</th>\n",
       "      <td>Crypto traders are once again betting on the v...</td>\n",
       "      <td>KAMA hit an all-time high of 2.4 cents in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-22</th>\n",
       "      <td>The spot ether ETFs are set to launch as soon ...</td>\n",
       "      <td>The spot ether ETFs are set to launch as soon ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-21</th>\n",
       "      <td>Trump's social media platform company isn’t th...</td>\n",
       "      <td>stock has risen higher as investors have rais...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-19</th>\n",
       "      <td>Hugh Hendry, famed former global macro hedge f...</td>\n",
       "      <td>Hugh Hendry is a former global macro hedge fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-19</th>\n",
       "      <td>XRP accounted for almost 40% of all trading ac...</td>\n",
       "      <td>XRP accounted for almost 40% of all trading ac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Description  \\\n",
       "Date                                                            \n",
       "2024-09-12  Digital-trading platform eToro USA agreed to p...   \n",
       "2024-09-12  High-leverage liquidity in bitcoin is concentr...   \n",
       "2024-09-11  The Kamala Harris-Donald Trump debate sent rip...   \n",
       "2024-09-11  US stocks (^DJI, ^IXIC, ^GSPC) were trading lo...   \n",
       "2024-09-11  Trump trades slumped following Tuesday's presi...   \n",
       "...                                                       ...   \n",
       "2024-07-22  Crypto traders are once again betting on the v...   \n",
       "2024-07-22  The spot ether ETFs are set to launch as soon ...   \n",
       "2024-07-21  Trump's social media platform company isn’t th...   \n",
       "2024-07-19  Hugh Hendry, famed former global macro hedge f...   \n",
       "2024-07-19  XRP accounted for almost 40% of all trading ac...   \n",
       "\n",
       "                                            Short Description  \n",
       "Date                                                           \n",
       "2024-09-12   eToro USA has agreed to limit its crypto offe...  \n",
       "2024-09-12   in bitcoin is concentrated at around $58,500,...  \n",
       "2024-09-11  The Kamala Harris-Donald Trump debate sent rip...  \n",
       "2024-09-11  US stocks are trading lower on Wednesday morni...  \n",
       "2024-09-11  Trump trades slumped following Tuesday's presi...  \n",
       "...                                                       ...  \n",
       "2024-07-22  KAMA hit an all-time high of 2.4 cents in the ...  \n",
       "2024-07-22  The spot ether ETFs are set to launch as soon ...  \n",
       "2024-07-21   stock has risen higher as investors have rais...  \n",
       "2024-07-19  Hugh Hendry is a former global macro hedge fun...  \n",
       "2024-07-19  XRP accounted for almost 40% of all trading ac...  \n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23ffc4c0-c105-48ae-a5d3-68f24fdb5f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/yahoo_bitcoin_news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ae10ee4-de70-4738-8fc7-24b3cdcf3a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
